{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import renom as rm\n",
    "from renom.optimizer import Adam, Adagrad\n",
    "from renom.cuda import set_cuda_active\n",
    "# if you would like to use GPU, set True, otherwise you should be set to False\n",
    "set_cuda_active(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_dataset(data, look_back, pred_length, class_num):\n",
    "    exp, target = [], []\n",
    "    for i in range(len(data) - look_back - pred_length):\n",
    "        exp.append(data[i : i+look_back, :])\n",
    "        target.append(data[i + look_back : i + look_back + pred_length, -3:].T)\n",
    "        \n",
    "    n_features = np.array(exp).shape[2]\n",
    "    exp = np.reshape(np.array(exp), [-1, look_back, n_features])\n",
    "    target = np.reshape(np.array(target), [-1, class_num])\n",
    "    return exp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1):\n",
    "    pos = int(round(len(X) * (1-test_size)))\n",
    "    X_train, y_train = X[:pos], y[:pos]\n",
    "    X_test, y_test = X[pos:], y[pos:]\n",
    "    return X_train, y_train, X_test, y_test, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../intermediate_data/prep_for_class_USDJPY_M15_20100101@000000_20180823@000000.pkl', mode='rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df = df.drop('delta_close', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df.copy()\n",
    "stds, means = [], []\n",
    "cols = []\n",
    "for col in df:\n",
    "    if (col != 'up') & (col != 'down') & (col != 'nochange'):\n",
    "        std = df[col].std()\n",
    "        mean = df[col].mean()\n",
    "        df_std[col] = (df[col] - mean) / std\n",
    "        stds.append(std)\n",
    "        means.append(mean)\n",
    "data = np.array(df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "pred_length = 1\n",
    "class_num = 3\n",
    "# X, y = create_dataset(data, look_back, pred_length)\n",
    "X, y = create_class_dataset(data, look_back, pred_length, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, pos = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential = rm.Sequential([\n",
    "    rm.Lstm(30),\n",
    "#     rm.Dropout(0.2),\n",
    "    rm.Lstm(20),\n",
    "#     rm.Dropout(0.2),\n",
    "#     rm.Dense(pred_length)\n",
    "    rm.Dense(class_num)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0000 loss:1.05331 test_loss:1.07072\n",
      "epoch:0010 loss:1.04185 test_loss:1.06429\n",
      "epoch:0020 loss:1.04022 test_loss:1.06566\n",
      "epoch:0030 loss:1.03931 test_loss:1.06383\n",
      "epoch:0040 loss:1.03868 test_loss:1.06458\n",
      "epoch:0050 loss:1.03834 test_loss:1.06244\n",
      "epoch:0060 loss:1.03777 test_loss:1.06185\n",
      "epoch:0070 loss:1.03751 test_loss:1.06304\n",
      "epoch:0080 loss:1.03713 test_loss:1.06174\n",
      "epoch:0090 loss:1.03682 test_loss:1.06380\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epoch = 1000\n",
    "N = len(X_train)\n",
    "T = X_train.shape[1]\n",
    "\n",
    "learning_curve = []\n",
    "test_learning_curve = []\n",
    "optimizer = Adagrad()\n",
    "for i in range(epoch):\n",
    "    loss = 0\n",
    "    test_loss = 0\n",
    "    perm = np.random.permutation(N)\n",
    "    for j in range(N//batch_size):\n",
    "        train_batch = X_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "        response_batch = y_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "        l = 0\n",
    "        with sequential.train():\n",
    "            for t in range(T):\n",
    "                z = sequential(train_batch[:, t, :])\n",
    "                l = rm.softmax_cross_entropy(z, response_batch)\n",
    "            sequential.truncate()\n",
    "        l.grad().update(optimizer)\n",
    "        loss += l.as_ndarray()\n",
    "    loss = loss / (N // batch_size)\n",
    "    l_test = 0\n",
    "    for t in range(T):\n",
    "        z = sequential(X_test[:, t, :])\n",
    "        l_test = rm.softmax_cross_entropy(z, y_test)\n",
    "    sequential.truncate()\n",
    "    test_loss += l_test.as_ndarray()\n",
    "    if i % 10 == 0:\n",
    "        print(\"epoch:{:04d} loss:{:.5f} test_loss:{:.5f}\".format(i, loss, test_loss))\n",
    "    learning_curve.append(loss)\n",
    "    test_learning_curve.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(learning_curve, label='loss')\n",
    "plt.plot(test_learning_curve, label='test_loss', alpha=0.6)\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test value\n",
    "for t in range(T):\n",
    "    y_test_pred = sequential(X_test[:, t, :])\n",
    "sequential.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train value\n",
    "for t in range(T):\n",
    "    y_train_pred = sequential(X_train[:, t, :])\n",
    "sequential.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.array(np.argmax(y_train_pred, axis=1))\n",
    "test_pred = np.array(np.argmax(y_test_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = np.argmax(y_train, axis=1)\n",
    "test_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3    0  859]\n",
      " [   2    0  866]\n",
      " [   3    2 5557]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.00      0.01       862\n",
      "          1       0.00      0.00      0.00       868\n",
      "          2       0.76      1.00      0.87      5562\n",
      "\n",
      "avg / total       0.63      0.76      0.66      7292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_true, test_pred))\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential.save(\"../class_model/lstm_{}_{}.h5\".format(gran, look_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../class_model/std_scaler_{}.pickle'.format(gran), mode='wb') as f:\n",
    "    pickle.dump(stds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../class_model/mean_scaler_{}.pickle'.format(gran), mode='wb') as f:\n",
    "    pickle.dump(means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
